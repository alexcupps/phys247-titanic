{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic Machine Learning Data Trainer\n",
    "- In this notebook, we will analyze the test data and attempt to predict the outcomes for the missing people. Given the data we have, can we accurately predict whether the rest of the people lived or died?\n",
    "- First, we will want to do manual research on the data we have. Are there any trends (gender, ticket class, age, etc.) that represent a strong-ish correlation with survival rate?\n",
    "\n",
    "Data Information\n",
    "\n",
    "(1) train.csv\n",
    "- train.csv contains the details of a subset of the passengers on board (891 passengers, to be exact -- where each passenger gets a different row in the table).\n",
    "\n",
    "- The values in the second column (\"Survived\") can be used to determine whether each passenger survived or not:\n",
    "- if it's a \"1\", the passenger survived.\n",
    "- if it's a \"0\", the passenger died.\n",
    "\n",
    "(2) test.csv\n",
    "- Using the patterns you find in train.csv, you have to predict whether the other 418 passengers on board (in test.csv) survived.\n",
    "\n",
    "- Note that test.csv does not have a \"Survived\" column - this information is hidden from you, and how well you do at predicting these hidden values will determine how highly you score in the competition!\n",
    "\n",
    "(3) gender_submission.csv\n",
    "- The gender_submission.csv file is provided as an example that shows how you should structure your predictions. It predicts that all female passengers survived, and all male passengers died. Your hypotheses regarding survival will probably be different, which will lead to a different submission file. But, just like this file, your submission should have:\n",
    "\n",
    "- a \"PassengerId\" column containing the IDs of each passenger from test.csv.\n",
    "- a \"Survived\" column (that you will create!) with a \"1\" for the rows where you think the passenger survived, and a \"0\" where you predict that the passenger died.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of 1st class passengers that survived: 0.6296296296296297\n",
      "% of 2nd class passengers that survived: 0.47282608695652173\n",
      "% of 3rd class passengers that survived: 0.24236252545824846\n"
     ]
    }
   ],
   "source": [
    "# Here, we are looking at the survival rate of each class\n",
    "first_class = train_data.loc[train_data.Pclass == 1][\"Survived\"]\n",
    "rate_first = sum(first_class)/len(first_class)\n",
    "\n",
    "second_class = train_data.loc[train_data.Pclass == 2][\"Survived\"]\n",
    "rate_second = sum(second_class)/len(second_class)\n",
    "\n",
    "third_class = train_data.loc[train_data.Pclass == 3][\"Survived\"]\n",
    "rate_third = sum(third_class)/len(third_class)\n",
    "\n",
    "print(\"% of 1st class passengers that survived:\", rate_first)\n",
    "print(\"% of 2nd class passengers that survived:\", rate_second)\n",
    "print(\"% of 3rd class passengers that survived:\", rate_third)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the survival rates of first, second and third class passengers, there is clear correlation between a passenger's ticket class and likelihood to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of C port passengers: 168\n",
      "Total # of Q port passengers: 77\n",
      "Total # of S port passengers: 644\n",
      "% of C port passengers that survived: 0.5535714285714286\n",
      "% of Q port passengers that survived: 0.38961038961038963\n",
      "% of S port passengers that survived: 0.33695652173913043\n"
     ]
    }
   ],
   "source": [
    "# Now, we want to see the rate of survival from each port to see if there is some connection there\n",
    "print(\"Total # of C port passengers:\", len(train_data.loc[train_data.Embarked == 'C']))\n",
    "print(\"Total # of Q port passengers:\", len(train_data.loc[train_data.Embarked == 'Q']))\n",
    "print(\"Total # of S port passengers:\", len(train_data.loc[train_data.Embarked == 'S']))\n",
    "\n",
    "c_port = train_data.loc[train_data.Embarked == 'C'][\"Survived\"]\n",
    "rate_cport = sum(c_port)/len(c_port)\n",
    "\n",
    "q_port = train_data.loc[train_data.Embarked == 'Q'][\"Survived\"]\n",
    "rate_qport = sum(q_port)/len(q_port)\n",
    "\n",
    "s_port = train_data.loc[train_data.Embarked == 'S'][\"Survived\"]\n",
    "rate_sport = sum(s_port)/len(s_port)\n",
    "\n",
    "print(\"% of C port passengers that survived:\", rate_cport)\n",
    "print(\"% of Q port passengers that survived:\", rate_qport)\n",
    "print(\"% of S port passengers that survived:\", rate_sport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the survival rates above, there is indeed some correlation between the port the passenger departed from and their likelihood to survive. Although the sample sizes between passengers from each port are not very similar in size, it is worth noting these differences and referencing this feature in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average first class ticket without Parch and SibSp: 63.67251376146788\n",
      "Average second class ticket without Parch and SibSp: 14.06610576923077\n",
      "Average third class ticket without Parch and SibSp: 9.272051851851852\n"
     ]
    }
   ],
   "source": [
    "# Now we will start to look at fare prices\n",
    "# We will try to filter out some variables that might affect the price. It seems like Parch and SibSp is a high determining factor in the price, so we want to take this out of the equation for now.\n",
    "# Let's look at the fare prices of people whose SibSp and Parch are 0.\n",
    "# First, we are finding the average price of each class ticket so we have a range to go off of.\n",
    "\n",
    "class_1 = train_data['Pclass'] == 1\n",
    "class_2 = train_data['Pclass'] == 2\n",
    "class_3 = train_data['Pclass'] == 3\n",
    "no_parch = train_data['Parch'] == 0\n",
    "no_sib = train_data['SibSp'] == 0\n",
    "\n",
    "combined_cond1 = class_1 & no_parch & no_sib\n",
    "filtered_cond1 = train_data[combined_cond1]\n",
    "first_avg = filtered_cond1['Fare'].mean()\n",
    "\n",
    "\n",
    "combined_cond2 = class_2 & no_parch & no_sib\n",
    "filtered_cond2 = train_data[combined_cond2]\n",
    "second_avg = filtered_cond2['Fare'].mean()\n",
    "\n",
    "\n",
    "combined_cond3 = class_3 & no_parch & no_sib\n",
    "filtered_cond3 = train_data[combined_cond3]\n",
    "third_avg = filtered_cond3['Fare'].mean()\n",
    "\n",
    "print(\"Average first class ticket without Parch and SibSp:\", first_avg)\n",
    "print(\"Average second class ticket without Parch and SibSp:\", second_avg)\n",
    "print(\"Average third class ticket without Parch and SibSp:\", third_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of people who survived and paid over $64: 0.6864406779661016\n",
      "% of people who survived and paid between $14 and $54: 0.44642857142857145\n",
      "% of people who survived and paid below $14: 0.1962025316455696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_19212\\869163461.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  med_fare = train_data.loc[train_data.Fare < first_avg][train_data.Fare >= second_avg][\"Survived\"]\n"
     ]
    }
   ],
   "source": [
    "# Next, let's categorize those ticket cost averages as different rates, and look at survival.\n",
    "high_rate = train_data.loc[train_data.Fare >= first_avg][\"Survived\"]\n",
    "rate_high = sum(high_rate)/len(high_rate)\n",
    "\n",
    "med_fare = train_data.loc[train_data.Fare < first_avg][train_data.Fare >= second_avg][\"Survived\"]\n",
    "rate_med = sum(med_fare)/len(med_fare)\n",
    "\n",
    "low_fare = train_data.loc[train_data.Fare <= third_avg][\"Survived\"]\n",
    "rate_low = sum(low_fare)/len(low_fare)\n",
    "\n",
    "print(\"% of people who survived and paid over $64:\", rate_high)\n",
    "print(\"% of people who survived and paid between $14 and $54:\",  rate_med)\n",
    "print(\"% of people who survived and paid below $14:\", rate_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ater reviewing the correlation between ticket price and ticket class, it is evident that ticket price and ticket class play a factor in survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ticket price from port C without Parch and SibSp: 49.75661882352942\n",
      "Average ticket price from port Q without Parch and SibSp: 8.382970175438595\n",
      "Average ticket price from port S without Parch and SibSp: 16.641684223918578\n"
     ]
    }
   ],
   "source": [
    "embarked_C = train_data['Embarked'] == 'C'\n",
    "embarked_Q = train_data['Embarked'] == 'Q'\n",
    "embarked_S = train_data['Embarked'] == 'S'\n",
    "\n",
    "combined_condi1 = embarked_C & no_parch & no_sib\n",
    "filtered_condi1 = train_data[combined_condi1]\n",
    "c_port_avg = filtered_condi1['Fare'].mean()\n",
    "\n",
    "\n",
    "combined_condi2 = embarked_Q & no_parch & no_sib\n",
    "filtered_condi2 = train_data[combined_condi2]\n",
    "q_port_avg = filtered_condi2['Fare'].mean()\n",
    "\n",
    "\n",
    "combined_condi3 = embarked_S & no_parch & no_sib\n",
    "filtered_condi3 = train_data[combined_condi3]\n",
    "s_port_avg = filtered_condi3['Fare'].mean()\n",
    "\n",
    "\n",
    "print(\"Average ticket price from port C without Parch and SibSp:\", c_port_avg)\n",
    "print(\"Average ticket price from port Q without Parch and SibSp:\", q_port_avg)\n",
    "print(\"Average ticket price from port S without Parch and SibSp:\", s_port_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming out a bit, we will next calculate the T-statistic to compare the mean prices of tickets for passengers that survived and those that did not, and confirm there is a significant difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-stat: 7.939191660871055 --- P-value: 6.120189341924198e-15\n"
     ]
    }
   ],
   "source": [
    "survived_fare = train_data[train_data['Survived'] == 1]['Fare']\n",
    "not_survived_fare = train_data[train_data['Survived'] == 0]['Fare']\n",
    "\n",
    "t_stat, p_val = ttest_ind(survived_fare, not_survived_fare, nan_policy='omit')\n",
    "print(f\"T-stat: {t_stat} --- P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a P-value of essentially zero, we reject the null hypothesis and can confidently say that there is significant difference between the mean ticket prices of the survived and not survived groups.\n",
    "\n",
    "Next, we will look into passenger gender, and see if it is correlated with survival rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of men who survived: 0.18890814558058924\n",
      "% of women who survived: 0.7420382165605095\n"
     ]
    }
   ],
   "source": [
    "women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n",
    "rate_men = sum(men)/len(men)\n",
    "\n",
    "print(\"% of men who survived:\", rate_men)\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above rates when comparing men and women, it is clear that gender is a highly correlated attribute to survival rate. Let's dive a little deeper into this, and see if age has any significant correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of children who survived: 0.5398230088495575\n"
     ]
    }
   ],
   "source": [
    "child = train_data.loc[train_data.Age < 18][\"Survived\"]\n",
    "rate_child = sum(child)/len(child)\n",
    "\n",
    "print(\"% of children who survived:\", rate_child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a survival rate of ~50% for children (both male and female) under the age of 18, this does not tell us much. However, I have a feeling that this rate could be skewed by males that were closer to that age threshold (i.e. teenage boys). I could see a world where boys that were old enough to not be considered \"children\" may have not had priority spots on the lifeboats. Let's dig into this a bit further, and see if we can uncover any trends when considering age and gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of boys who survived (under 5 years old): 0.6521739130434783\n",
      "% of boys who survived (under 12 years old): 0.5555555555555556\n",
      "% of boys who survived (under 18 years old): 0.39655172413793105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_19212\\975798654.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  child_male_sub_5 = train_data.loc[train_data.Age < 5][train_data.Sex == 'male'][\"Survived\"]\n",
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_19212\\975798654.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  child_male_sub_12 = train_data.loc[train_data.Age < 12][train_data.Sex == 'male'][\"Survived\"]\n",
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_19212\\975798654.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  child_male_sub_18 = train_data.loc[train_data.Age < 18][train_data.Sex == 'male'][\"Survived\"]\n"
     ]
    }
   ],
   "source": [
    "child_male_sub_5 = train_data.loc[train_data.Age < 5][train_data.Sex == 'male'][\"Survived\"]\n",
    "rate_child_male_sub_5 = sum(child_male_sub_5)/len(child_male_sub_5)\n",
    "\n",
    "child_male_sub_12 = train_data.loc[train_data.Age < 12][train_data.Sex == 'male'][\"Survived\"]\n",
    "rate_child_male_sub_12 = sum(child_male_sub_12)/len(child_male_sub_12)\n",
    "\n",
    "child_male_sub_18 = train_data.loc[train_data.Age < 18][train_data.Sex == 'male'][\"Survived\"]\n",
    "rate_child_male_sub_18 = sum(child_male_sub_18)/len(child_male_sub_18)\n",
    "\n",
    "print(\"% of boys who survived (under 5 years old):\", rate_child_male_sub_5)\n",
    "print(\"% of boys who survived (under 12 years old):\", rate_child_male_sub_12)\n",
    "print(\"% of boys who survived (under 18 years old):\", rate_child_male_sub_18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these survival rates, it is evident that younger boys that could be considered babies/infants had a much higher chance of survival than older boys. Let's take a look at these same rates for girls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of girls who survived (under 5 years old): 0.7058823529411765\n",
      "% of girls who survived (under 12 years old): 0.59375\n",
      "% of girls who survived (under 18 years old): 0.6909090909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_19212\\851560439.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  child_female_sub_5 = train_data.loc[train_data.Age < 5][train_data.Sex == 'female'][\"Survived\"]\n",
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_19212\\851560439.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  child_female_sub_12 = train_data.loc[train_data.Age < 12][train_data.Sex == 'female'][\"Survived\"]\n",
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_19212\\851560439.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  child_female_sub_18 = train_data.loc[train_data.Age < 18][train_data.Sex == 'female'][\"Survived\"]\n"
     ]
    }
   ],
   "source": [
    "child_female_sub_5 = train_data.loc[train_data.Age < 5][train_data.Sex == 'female'][\"Survived\"]\n",
    "rate_child_female_sub_5 = sum(child_female_sub_5)/len(child_female_sub_5)\n",
    "\n",
    "child_female_sub_12 = train_data.loc[train_data.Age < 12][train_data.Sex == 'female'][\"Survived\"]\n",
    "rate_child_female_sub_12 = sum(child_female_sub_12)/len(child_female_sub_12)\n",
    "\n",
    "child_female_sub_18 = train_data.loc[train_data.Age < 18][train_data.Sex == 'female'][\"Survived\"]\n",
    "rate_child_female_sub_18 = sum(child_female_sub_18)/len(child_female_sub_18)\n",
    "\n",
    "print(\"% of girls who survived (under 5 years old):\", rate_child_female_sub_5)\n",
    "print(\"% of girls who survived (under 12 years old):\", rate_child_female_sub_12)\n",
    "print(\"% of girls who survived (under 18 years old):\", rate_child_female_sub_18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is a strange dip in the survival rate of girls between ages 5-11, it is notable that the survival rate of female babies/infants is very similar to the overall rate of girls under the age of 18. This goes to show that the age discrepancy between female childeren did not share the same impact on survival rate that it did on male children.\n",
    "\n",
    "Overall, it is clear that the age of the passenger has significant correlation with the survival rate, especially when looking at gender and age together. We will want to keep that in mind when training our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you can see the total count of rows missing values for the respective features (i.e. there are 177 rows missing a value for \"Age\"). We will want to make sure to clean these rows before using them in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('results-random-forest.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting this results CSV file to Kaggle, we discovered that our Random Forest Classifier model successfully predicted the survival of 77.5% of our test data. While this is reasonably accurate, ideally we'd like to increase that accuracy rate by a bit. Let's try creating a sequential model using Keras and see how the results compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0            1         0       3    male  22.0      1      0   7.2500        S\n",
       "1            2         1       1  female  38.0      1      0  71.2833        C\n",
       "2            3         1       3  female  26.0      0      0   7.9250        S\n",
       "3            4         1       1  female  35.0      1      0  53.1000        S\n",
       "4            5         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_train_data = pd.read_csv(\"train.csv\")\n",
    "keras_test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Drop the fields we don't care about from the data\n",
    "drop_fields = ['Ticket', 'Cabin', 'Name']\n",
    "def clean_data(data, droppable):\n",
    "    if pd.Series(droppable).isin(data.columns).all():  \n",
    "        for field in droppable:\n",
    "            data.drop(field, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "clean_data(keras_train_data, drop_fields)\n",
    "clean_data(keras_test_data, drop_fields)\n",
    "\n",
    "keras_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned our data, let's convert the categorical variables to numeric values. Our categorical variables are Sex and Embarked (both nominal). We'll use the get_dummies() function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras_train_data shape: (891, 10)\n",
      "keras_test_data shape: (418, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.283302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch       Fare  Sex_male  \\\n",
       "0          1.0       0.0     3.0  22.0    1.0    0.0   7.250000       1.0   \n",
       "1          2.0       1.0     1.0  38.0    1.0    0.0  71.283302       0.0   \n",
       "2          3.0       1.0     3.0  26.0    0.0    0.0   7.925000       0.0   \n",
       "3          4.0       1.0     1.0  35.0    1.0    0.0  53.099998       0.0   \n",
       "4          5.0       0.0     3.0  35.0    0.0    0.0   8.050000       1.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0         0.0         1.0  \n",
       "1         0.0         0.0  \n",
       "2         0.0         1.0  \n",
       "3         0.0         1.0  \n",
       "4         0.0         1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_features(data, features):\n",
    "    if pd.Series(features).isin(data.columns).all():\n",
    "        data = pd.get_dummies(data, columns=features, drop_first=True)\n",
    "    return data\n",
    "\n",
    "nominal_features = ['Sex', 'Embarked']\n",
    "keras_train_data = convert_features(keras_train_data, nominal_features)\n",
    "keras_test_data = convert_features(keras_test_data, nominal_features)\n",
    "\n",
    "# fill null values if any exist\n",
    "keras_train_data.fillna(keras_train_data.mean(), inplace=True)\n",
    "keras_test_data.fillna(keras_test_data.mean(), inplace=True)\n",
    "\n",
    "# make sure the columns are aligned\n",
    "keras_test_data = keras_test_data[keras_train_data.columns.drop('Survived')]\n",
    "\n",
    "keras_test_data = keras_test_data.astype(np.float32)\n",
    "keras_train_data = keras_train_data.astype(np.float32)\n",
    "\n",
    "print(f'keras_train_data shape: {keras_train_data.shape}')\n",
    "print(f'keras_test_data shape: {keras_test_data.shape}')\n",
    "\n",
    "keras_train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felix\\PycharmProjects\\phys247-titanic\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Felix\\PycharmProjects\\phys247-titanic\\.venv\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5723 - loss: 0.7298 - val_accuracy: 0.7654 - val_loss: 0.6139 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7750 - loss: 0.5132 - val_accuracy: 0.7877 - val_loss: 0.5542 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.4935 - val_accuracy: 0.8045 - val_loss: 0.5179 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.4963 - val_accuracy: 0.8212 - val_loss: 0.4936 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8071 - loss: 0.4619 - val_accuracy: 0.8045 - val_loss: 0.4718 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4669 - val_accuracy: 0.8045 - val_loss: 0.4549 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.4334 - val_accuracy: 0.8045 - val_loss: 0.4434 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4609 - val_accuracy: 0.8156 - val_loss: 0.4328 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7995 - loss: 0.4521 - val_accuracy: 0.8212 - val_loss: 0.4313 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.4904 - val_accuracy: 0.8268 - val_loss: 0.4242 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.4361 - val_accuracy: 0.8212 - val_loss: 0.4248 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7972 - loss: 0.4713 - val_accuracy: 0.8156 - val_loss: 0.4321 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4502 - val_accuracy: 0.8212 - val_loss: 0.4295 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4540 - val_accuracy: 0.8101 - val_loss: 0.4322 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.4180 - val_accuracy: 0.8045 - val_loss: 0.4336 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.4190 - val_accuracy: 0.8156 - val_loss: 0.4356 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8208 - loss: 0.4175 - val_accuracy: 0.8268 - val_loss: 0.4351 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.4303 - val_accuracy: 0.8156 - val_loss: 0.4405 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8479 - loss: 0.3831 - val_accuracy: 0.8156 - val_loss: 0.4438 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.4284 - val_accuracy: 0.8101 - val_loss: 0.4410 - learning_rate: 0.0010\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Prepare data\n",
    "X_train = keras_train_data.drop('Survived', axis=1)\n",
    "y_train = keras_train_data['Survived']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(keras_test_data)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_train, test_size=0.2, random_state=222)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(256, input_dim=X_train.shape[1]),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.3),\n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.3),\n",
    "    Dense(64),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.3),\n",
    "    Dense(32),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Make predictions\n",
    "predictions = (model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Prepare submission file\n",
    "submission = pd.DataFrame({'PassengerId': test_data['PassengerId'].astype('int32'), 'Survived': predictions})\n",
    "submission.to_csv('results-keras.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4442 \n",
      "Model Accuracy: 0.826815664768219\n",
      "Model Loss: 0.42419037222862244\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "print(f'Model Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
